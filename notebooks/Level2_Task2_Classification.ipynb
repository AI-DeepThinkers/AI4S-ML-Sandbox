{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eee6596",
   "metadata": {},
   "source": [
    "# Level 2 \n",
    "## Task 2: Classification\n",
    "\n",
    "Welcome to this notebook for Level 2 Task 2: **Classification**.  \n",
    "In this task, we'll explore how to:\n",
    "\n",
    "- Load and preview cleaned datasets\n",
    "- Configure a classification pipeline\n",
    "- Train and evaluate two models: Logistic Regression and Random Forest\n",
    "- Analyze their performance with accuracy and confusion matrices\n",
    "\n",
    "This notebook is interactive and modular—you're encouraged to experiment with your own dataset as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0e073e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Imports --------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "from ipywidgets import Output, VBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "58a92e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Paths & Defaults --------------------\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "cleaned_dir = os.path.join(root_dir, \"data\", \"cleaned\")\n",
    "\n",
    "default_file = \"iris_cleaned.csv\"  # or any available cleaned dataset\n",
    "available_csvs = [f for f in os.listdir(cleaned_dir) if f.endswith(\".csv\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1691662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Widgets --------------------\n",
    "file_selector = widgets.Dropdown(options=available_csvs, value=default_file, description=\"File:\")\n",
    "file_upload = widgets.FileUpload(accept=\".csv\", multiple=False)\n",
    "target_selector = widgets.Dropdown(options=[], description=\"Target:\")\n",
    "feature_selector = widgets.SelectMultiple(options=[], description=\"Features\")\n",
    "run_button = widgets.Button(description=\"Run Classification\", button_style='success')\n",
    "\n",
    "# UI containers\n",
    "dataset_ui = Output()\n",
    "output_area = Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b3509fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Choose or Upload a Dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a5c9a4207649998e8eea13bb111e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='File:', index=2, options=('churn-bigml-20_cleaned.csv', 'house_prediction_cleaned.csv', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e325b5033789492b80e9f985bc8e04a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.csv', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379f6c2327b645f08a80d34a89cecfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_dataset(file_path=None, uploaded=None):\n",
    "    try:\n",
    "        if uploaded:\n",
    "            return pd.read_csv(io.BytesIO(uploaded['content']))\n",
    "        elif file_path:\n",
    "            return pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            print(f\"❌ Failed to load dataset: {e}\")\n",
    "    return None\n",
    "\n",
    "# -------------------- Update full dataset section --------------------\n",
    "def render_dataset_ui(df):\n",
    "    global current_df\n",
    "    current_df = df  # Set current dataset\n",
    "    \n",
    "    dataset_ui.clear_output()\n",
    "    \n",
    "    with dataset_ui:\n",
    "        display(Markdown(\"## Dataset Preview\"))\n",
    "        display(Markdown(\"The loaded dataset is displayed below. This helps you understand the available columns before choosing your target and features.\"))\n",
    "        display(df.head())\n",
    "\n",
    "        # Update selector options\n",
    "        \n",
    "\n",
    "        target_selector.options = df.columns.tolist()\n",
    "        feature_selector.options = df.columns.tolist()\n",
    "        target_selector.value = df.columns[-1]\n",
    "        feature_selector.value = tuple(col for col in df.columns if col != target_selector.value)\n",
    "\n",
    "        display(Markdown(\"## Configure Target & Features\"))\n",
    "        display(Markdown(\"Choose which column to use as the **target** (classification label),  \\n\"\n",
    "                         \"and select one or more **numeric** columns to use as features.\"))\n",
    "        display(target_selector, feature_selector, run_button)\n",
    "\n",
    "# -------------------- Handle Dataset Change --------------------\n",
    "def on_file_selected(change=None):\n",
    "    path = os.path.join(cleaned_dir, file_selector.value)\n",
    "    df = load_dataset(file_path=path)\n",
    "    if df is not None:\n",
    "        render_dataset_ui(df)\n",
    "\n",
    "def on_file_uploaded(change):\n",
    "    uploaded = list(file_upload.value.values())[0]\n",
    "    df = load_dataset(uploaded=uploaded)\n",
    "    if df is not None:\n",
    "        render_dataset_ui(df)  # fully redraw preview + config\n",
    "\n",
    "file_selector.observe(on_file_selected, names='value')\n",
    "file_upload.observe(on_file_uploaded, names='value')\n",
    "\n",
    "# Display UI blocks\n",
    "display(Markdown(\"## Choose or Upload a Dataset\"))\n",
    "display(file_selector, file_upload)\n",
    "display(dataset_ui)  # will show preview & config\n",
    "# display(output_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d39cea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the default dataset (e.g., Iris dataset) for auto-loading\n",
    "default_df_path = os.path.join(cleaned_dir, default_file)\n",
    "df_default  = load_dataset(file_path=default_df_path)\n",
    "\n",
    "if df_default is not None:\n",
    "    render_dataset_ui(df_default)\n",
    "else:\n",
    "    with dataset_ui:\n",
    "        print(\"❌ Could not load default dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615414d1",
   "metadata": {},
   "source": [
    "## Train & Evaluate Classification Models\n",
    "\n",
    "We'll train two models and evaluate their performance using:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n",
    "- Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5f92889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_classification_target(y):\n",
    "    return y.dtype == 'O' or (y.nunique() <= 20 and np.all(np.equal(np.mod(y, 1), 0)))\n",
    "\n",
    "def plot_confusion(cm, labels, title):\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels, cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ba508d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------  Run Classification --------------------\n",
    "def train_and_evaluate(df, target_col, feature_cols):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "   \n",
    "\n",
    "        if not feature_cols:\n",
    "            print(\"Please select at least one feature.!\")\n",
    "            return\n",
    "\n",
    "        X = df[list(feature_cols)]\n",
    "        y = df[target_col]\n",
    "\n",
    "        if not is_classification_target(y):\n",
    "            print(\"Target is not suitable for classification.!!!\")\n",
    "            return\n",
    "\n",
    "        if X.select_dtypes(exclude=[\"number\"]).shape[1] > 0:\n",
    "            print(\"Only numeric features are supported.!!!\")\n",
    "            return\n",
    "\n",
    "        # Encode target\n",
    "        if y.dtype == 'O':\n",
    "            le = LabelEncoder()\n",
    "            y = le.fit_transform(y)\n",
    "            class_labels = le.classes_\n",
    "        else:\n",
    "            class_labels = sorted(y.unique())\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        models = {\n",
    "            \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "            \"Random Forest\": RandomForestClassifier()\n",
    "        }\n",
    "\n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_test)\n",
    "\n",
    "            display(Markdown(f\"### {name}\"))\n",
    "            display(Markdown(f\"**Accuracy:** {accuracy_score(y_test, preds):.2f}\"))\n",
    "            display(Markdown(f\"**Precision:** {precision_score(y_test, preds, average='macro'):.2f}\"))\n",
    "            display(Markdown(f\"**Recall:** {recall_score(y_test, preds, average='macro'):.2f}\"))\n",
    "            display(Markdown(f\"**F1 Score:** {f1_score(y_test, preds, average='macro'):.2f}\"))\n",
    "\n",
    "            cm = confusion_matrix(y_test, preds)\n",
    "            plot_confusion(cm, class_labels, f\"{name} – Confusion Matrix\")\n",
    "\n",
    "        print(\"\\n📋 Classification Report:\")\n",
    "        print(classification_report(y_test, preds, target_names=class_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5f3cf6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_run_clicked(b):\n",
    "    path = os.path.join(cleaned_dir, file_selector.value)\n",
    "    df = load_dataset(file_path=path)\n",
    "    if df is not None:\n",
    "        train_and_evaluate(df, target_selector.value, feature_selector.value)\n",
    "\n",
    "run_button.on_click(on_run_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fa2a4ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Classification Output"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b3c3817b4f4c0888a6dc7bb25378d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the output area at the end where results will show\n",
    "display(Markdown(\"## Classification Output\"))\n",
    "display(output_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d4675d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-load iris and run once\n",
    "on_file_selected()\n",
    "on_run_clicked(None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae2c747",
   "metadata": {},
   "source": [
    "## ✅ Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "- Interactively loaded datasets\n",
    "- Configured classification features and targets\n",
    "- Trained and evaluated models using multiple metrics\n",
    "- Visualized performance using confusion matrices\n",
    "\n",
    "Feel free to explore other datasets or upload your own. Happy modeling! 🎉\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codveda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
