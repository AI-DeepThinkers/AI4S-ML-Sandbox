# Level 1 Task 1: Web Scraping

Welcome to **Task 1** a project focused on collecting and extracting structured data from websites using web scraping techniques.

---

## ğŸ“– Overview

This task demonstrates how to:

- Detect if a page is **static or dynamic**
- Scrape data from a default site (`http://quotes.toscrape.com`)
- Allow users to input a custom URL and extract readable content
- Display extracted data using **Streamlit** with a clean UI

---

## ğŸš€ Features

- âœ… **Built-in Demo Scraper**: Collects quotes, authors, and tags from a static site
- âœ… **Custom URL Support**: Accepts any user-defined URL and:
  - Checks if the page is static or dynamic
  - Extracts visible readable content (titles, paragraphs, lists)
- âœ… **Heuristic Page Type Detection** using length differences between raw HTML and Selenium-rendered DOM
- âœ… **Markdown-formatted output** for improved readability
- âœ… **Polite Scraping** using delay and user-agent headers

---

## ğŸ§° Tech Stack

- `Python`
- `BeautifulSoup`
- `requests`
- `Selenium`
- `pandas`
- `Streamlit`

---

## ğŸ—‚ï¸ Project Structure

```bash
root/
â”‚
â”œâ”€â”€ Level1_Basic/
â”‚   â””â”€â”€ Task1_Scraping/
â”‚       â”œâ”€â”€ scraper.py              # Core scraping logic
â”‚       â””â”€â”€ sample_outputs/         # Example scraped CSV/JSON files
â”‚
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ app_pages/
â”‚   â”‚   â””â”€â”€ level1_task1_scraping.py   # Streamlit UI
â”‚   â””â”€â”€ streamlit_app.py               # Main multi-page launcher (optional)
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ quotes.csv / quotes.json       # Output files
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

-- 
## ğŸ“¦ Setup Instructions

1. Clone the repository


2. Create and activate a virtual environment
bash
python -m venv
env\Scripts\activate     # Windows
source env/bin/activate # macOS/Linux

3. Install dependencies
bash
pip install -r requirements.txt

4. Launch Streamlit app
bash
cd streamlit_app/app_pages
streamlit run level1_task1_scraping.py


## ğŸ§ª Demo Site Used
- URL: http://quotes.toscrape.com
- Public, static, and intentionally built for scraping practice

## ğŸ“¤ Outputs
- quotes.csv and quotes.json saved in /data/
- Cleaned and tagged content from user-defined URLs shown in browser

## ğŸ§  Learnings
This task taught foundational web scraping skills and introduced ethical scraping practices and how to work with both static and dynamic websites.

ğŸ“¸ Preview
<!-- Optional: Include a screenshot -->

## ğŸ”– Hashtags for LinkedIn
txt
| #WebScraping #Python #Streamlit #BeautifulSoup #InternshipProject


